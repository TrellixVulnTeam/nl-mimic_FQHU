{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Attempt\n",
    "Max Fierro 2/20/2022\n",
    "\n",
    "### From Deterministic and Stochastic Predictions to Performing Lookups on an Adjacency Matrix\n",
    "\n",
    "This is my first exercise working with both a jupyter notebook and the concept of a Markov chain. The idea is one I was briefly exposed to as a sidenote in one of my classes, CS61a at UC Berkeley in Fall '21. I think I remember one of my instructors, Pamela Fox, briefly going into a tangent of how you could sort of emulate what someone could say by making a 'dictionary' of words from a text, in such a way that every `key:value` pair is every `word:nextword`. It's pretty simple, and it has the somewhat cool property that obtaining `dict[word]` would (if computers were not so annoyingly deterministic) fetch some `nextword`, where the probability of choosing it depends on the amount of times it appears after `word` divided by the total number of appearances of `word` in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial implementation\n",
    "\n",
    "This also being my first 'real' practical experience working with data, I thought I should be as verbose as possible and try to identify some of the challenges of working with data before trying to work with some libraries. While I know this is obviously not the most elegant way of doing this, the code is pretty easy to understand, and the methods allow for some good old `print` calls here and there if you want to see what is happening (TBH I also needed a tiny refresher with Python).\n",
    "\n",
    "BTW, I do not endorse the language used in 'Adventures of Huckleberry Finn' by Mark Twain, in case you are either stochastically or deterministically delivered a no-no word.\n",
    "\n",
    "   So! Here is what I came up with first:\n",
    "1. A `PairLink` class defining `word:nextword` pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PairLink:\n",
    "    \n",
    "    def __init__(self, key, value, unwanted = []):\n",
    "        self._unwanted = unwanted\n",
    "        self._val = value\n",
    "        self._key = key\n",
    "    \n",
    "    def clean(self, f):\n",
    "        def alter(elt):\n",
    "            if elt == None: return None\n",
    "            for item in self._unwanted:\n",
    "                if type(elt) == str:\n",
    "                    elt = elt.replace(item, '')\n",
    "            return f(elt) if f else elt\n",
    "        self._val = alter(self._val)\n",
    "        self._key = alter(self._key)\n",
    "    \n",
    "    def val(self):\n",
    "        return self._val\n",
    "    \n",
    "    def key(self):\n",
    "        return self._key\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self._key) + ' -> ' + str(self._val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A `MkvPool` class defining a collection of `PairLink`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MkvPool:\n",
    "    \n",
    "    def __init__(self, pair_link_list):\n",
    "        self._list = [l for l in pair_link_list]\n",
    "    \n",
    "    def clean_all(self, f):\n",
    "        [l.clean(f) for l in self._list]\n",
    "    \n",
    "    def item_list(self):\n",
    "        return [item for item in dic(self).keys()]\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self._list)\n",
    "    \n",
    "    def lst(self):\n",
    "        return self._list\n",
    "    \n",
    "    def dic(self):\n",
    "        return {l.key(): l.val() for l in self._list}\n",
    "    \n",
    "    def choose_with_key(self, key):\n",
    "        return [l for l in self._list if l.key() == key]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        repr([self.lst()])\n",
    "    \n",
    "    def next_deterministic(self, first):\n",
    "        k = {}\n",
    "        for l in self.lst():\n",
    "            if l.key() == first:\n",
    "                if l.val() not in k.keys():\n",
    "                    k[l.val()] = 1\n",
    "                else:\n",
    "                    k[l.val()] += 1\n",
    "        return max(k, key = k.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The function `read_txt` which unloads `chars` characters from a .txt file into a list of clean word strings free of `unwanted` characters, and `word_PairLinks` which turns them into `PairLink`s. This is where our data, \"Adventures of Huckleberry Finn,\" is processed. If you notice any redundancy, it is there so I can use `read_txt` later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(file, unwanted, chars = None):\n",
    "    doc = open(file)\n",
    "    data = doc.read(chars).split()\n",
    "    doc.close()\n",
    "    words = []\n",
    "    for word in data:\n",
    "        for item in unwanted:\n",
    "            word = word.replace(item, '')\n",
    "        word = word.lower()\n",
    "        words.append(word)\n",
    "    return words\n",
    "\n",
    "def word_PairLinks(words, unwanted):\n",
    "    links = [PairLink(None, words[0], unwanted)]\n",
    "    for i in range(len(words) - 2):\n",
    "        links.append(PairLink(words[i], words[i + 1], unwanted))\n",
    "    links.append(PairLink(words[-1], None, unwanted))\n",
    "    return links\n",
    "\n",
    "unwanted = ['\"', '^', '*', '-', '_', '/', '[', ']', '<', '>', '~', ',']\n",
    "\n",
    "words = read_words('data/huck_finn.txt', unwanted, 1000000)\n",
    "pool = MkvPool(word_PairLinks(words, unwanted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The funciton `make_chain` which creates a chain of words using some `choose_next_func` to choose the next word based on the current one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_chain(length, choose_next_func, seed = None):\n",
    "    counter, last = 0, seed\n",
    "    chain = '' if not seed else seed\n",
    "    while counter < length:\n",
    "        nxt = choose_next_func(last)\n",
    "        chain += ' ' + nxt if nxt != None else ''\n",
    "        last = nxt\n",
    "        counter += 1\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Some `choose_next_func`s, which deliver a following word stochastically and deterministically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_stochastically(last, bank = pool):\n",
    "    return random.choice(bank.choose_with_key(last)).val()\n",
    "\n",
    "def choose_deterministically(last, bank = pool):\n",
    "    return bank.next_deterministic(last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results (PairLink implementation)\n",
    "While this served its purpose as a first exercise, it obviously constitutes a very poor model when it comes to prediction. You would need to get very lucky to get something coherent. It also has a lot of unnecessary stuff which I made for the sake of killing time and reviewing Python, which probably made it very unefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deterministic chain:\n",
      "\n",
      " hello jim said he was a little and the king he was a little and the king he was a little and the king he was a little and the king\n",
      "\n",
      "Stochastic chain:\n",
      "\n",
      " hello jim got the new kind of them out only just as you needn't keep a rattling kick. but uncle and they'll soon he said they'd just to make certain. now\n",
      "\n",
      "Time elapsed for stochastic chain: 0.4450669288635254\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You can change the length and seed of the predictions. \n",
    "\n",
    "Notice how the output of the deterministic chain eventually stabilizes into\n",
    "repetition. Exercise for the reader: Determine, on average, after how many \n",
    "words the deterministic chain exhibits cyclic behavior given some seed word W \n",
    "in some dataset D.\n",
    "\n",
    "Now that I've left an exercise for the reader, I can die in peace.\n",
    "\"\"\"\n",
    "\n",
    "print('\\nDeterministic chain:\\n\\n', make_chain(30, choose_deterministically, 'hello'))\n",
    "start = time.time()\n",
    "print('\\nStochastic chain:\\n\\n', make_chain(30, choose_stochastically, 'hello'))\n",
    "print('\\nTime elapsed for stochastic chain:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for improvement\n",
    "\n",
    "To hopefully improve our performance, let's do a little bit of math. I'll define a matrix `M` with a column and row for each word, where $M_{i, j} = P(j | i)$. In other words, every element of $M$ will represent the probability that the word corresponding to its column follows the word corresponding to its row within the text we are analyzing. I read about this matrix representation somewhere a while ago, so while I am unable to point to a reference it should suffice to say that, unlike the last implementation, I did not come up with this by myself.\n",
    "\n",
    "The objective of making this matrix will be to determine which word should go after another more quickly, allowing us to make quicker predictions at the cost of a slower initial matrix computation. Again, I'll keep all libraries out of this for now for the sake of my learning, and the only thing I'll be using from the previous section is our `words` list, returned by `read_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(all_words):\n",
    "    \n",
    "    def init_matrix(uniques):\n",
    "        return [[0] * len(uniques) for i in range(len(uniques))]\n",
    "    \n",
    "    unique_words = list(set(all_words))\n",
    "    uw_indices = {word:unique_words.index(word) for word in unique_words}\n",
    "    M = init_matrix(unique_words)\n",
    "    successor_count = {}\n",
    "    \n",
    "    for i in range(len(all_words) - 1):\n",
    "        curr = uw_indices[all_words[i]]\n",
    "        nxt = uw_indices[all_words[i + 1]] \n",
    "        M[curr][nxt] += 1\n",
    "    \n",
    "    for i in range(len(M)):\n",
    "        successor_count[i] = sum(M[i])\n",
    "        M[i] = [p / successor_count[i] for p in M[i]]\n",
    "    \n",
    "    return M, unique_words, uw_indices\n",
    "\n",
    "M, Uwords, Uindices = create_matrix(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is set up such that $M_{i,j}$ = P(`Uword[j]` | `Uword[i]`), which I feel could be made simpler, but any improvements elude me at the moment. Anyway, we now have a matrix correlating each word and their possible successors probabilistically.\n",
    "\n",
    "Now, to create a `choose_next_func` which takes advantage of my hard work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_stochastic_matrix(last, m = M, uw = Uwords, ui = Uindices):\n",
    "    possible_words = m[ui[last]]\n",
    "    tmp, i = [], 0\n",
    "    for word in possible_words:\n",
    "        tmp += [[word, i]]\n",
    "        i += 1\n",
    "    result = random.choices(tmp, possible_words, k = 1)[0][1]\n",
    "    return uw[result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results (Matrix implementation)\n",
    "\n",
    "Again, I will not pretend that this model provides an accurate prediction of what Mark Twain would say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stochastic matrix prediction:\n",
      "\n",
      " hello jim says: miss them. gimme no more than what she was going to slide down the expense of use in town if i was worth of a town so on. i took a good place. she started her lights twinkling where my craw; but somehow it wouldn't be mighty smart. yes he done some little and shook and ready to the originator of men jumped in the oldest man to meand then pretty silly to get there; you 'bout? i must up very thick which was saying is i was all up my ears; and live! and your names. the\n",
      "\n",
      "Time elapsed for matrix chain: 8.515828847885132\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print('\\nStochastic matrix prediction:\\n\\n', make_chain(100, choose_stochastic_matrix, 'hello'))\n",
    "print('\\nTime elapsed for matrix chain:', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I have to admit I was not expecting that. My theory was that creating a matrix with all the probability information would save a lot of computation, and therefore a lot of time. But apparently not, and it instead consistently triples the time required to create a chain (at least for smaller output lengths -- I do not have the time to experiment with larger chains).\n",
    "\n",
    "Having completed that, I feel like I have gotten my foot in the door to working with Markov chains and with processing data, so I will call it a day. If you know why my hypothesis was incorrect or how to fix my implementation, please email me. I would love to know."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "a3eb2447a068bb7fb089a185ab5e46d0fb75c41e7929163dd0177d6c30f45c0c"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
